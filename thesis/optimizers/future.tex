The constant optimization step applied in our tool has been limited to simple constants in the expression. The tree representing the expression stores a hidden constant for each node that can act as linear weights. We can extend the constant optimization step to include these constants. The advantage is that the expression can be optimized to a greater extent. The disadvantage is the high increase in computational cost. Each constant represents a dimension for the constant optimizer. From our discussion we know that a high dimensionality has a serious impact on the complexity of the optimization step. Using the linear weights representation we could further simplify trees when applying constant folding. In this work we have seen how great the impact is from invalid expression on the runtime of the algorithm. If we use a set of base functions where the domain is identical for each, for example the Chebyshev polynomials, and rescale our input set then we could largely avoid the initialization issue. A domain expert should be able to give hints to the tool specifying which base functions are expected to be used. If this is uncertain a weighted set of functions could be introduced. If a sinusoid is expected, but other base functions cannot be excluded, we could bias the functionset by introducing weights steering the selection of base functions. This functionality is partially present in our tool. 