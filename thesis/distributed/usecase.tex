%%!TEX root = document.tex

 
Epidemiological simulation is a vital tool for policy makers since observed data is not fully predictive for new outbreaks in changing populations and experiments in the real world process can have practical, budgetary or ethical constraints. With a focus on the prevention and to obtain insights in transmission dynamics, simulations and surrogate modelling can be very useful using a configurable set of parameters mimicking real world process.

Our aim is to apply SR to the input-output mapping of a computationally intensive high performance simulator, STRIDE \citep{stride}, that models the transmission of infectious diseases.
The simulator is calibrated to model measles outbreaks in the city of Antwerp, Belgium, with a population size of 500000 individuals. Of vital importance here is the measles immunization aspect and as such, our research question is: how does the immunization fraction influence the outbreak of measles?
We will focus on the convergence characteristics of the surrogate models rather than their domain specific implications. 

A single simulation run with this individual-based model is computationally expensive hence surrogate models, approximating a simulator, can be useful as an emulator to improve model exploration and facilitate rapid policy making in various settings. 
Symbolic regression can be used to obtain surrogate models based on input-output simulation data. Generating all simulation output in sequence prior to building the surrogate model leads to significant downtime for the user. 
Therefore, we are also interested in the value of an incremental approach with surrogate models based on partial results of the simulation model. This is vital in order to setup a trustworthy feedback loop between the user, simulator and regression tool. 
This incremental approach,  provides partial results to a domain expert to enhance the model building and design of experiments. Our CRSE tool is able to reuse partial results as seeds for new runs. We elaborate in this section whether this approach can lead to improved models.

% please, limit the number of abbreviations to increase the readability for your audience
\paragraph{Design of experiment}
To run the disease transmission simulator, we used a space filling design to maximize the sampling of the parameter space and minimize the number of evaluation points. We apply a Latin Hypercube Design, specifically the Audze-Eglais \citep{AudzeEglais, AudzeEglais2, AudzeEglais3}, which uses the Euclidean distance measure but in addition obtains a uniform distribution of the individual points. This design relies on the concept of minimizing a potential energy between design points, a measure based on the inverse of the euclidean distance.
\[
E^{AE} = \sum_{i=0}^{p-1} {\sum_{j=i+1}^{p-1} {\frac{1}{d_{ij}}}}
\]

%\paragraph{Simulator configuration}
We constructed an experimental design with 3 dimensions and 30 points, using the tool introduced by Husslange et al. \citep{DOE}. We used the following parameters:
\begin{itemize}
\item Basic reproduction number (R$_0$) : the expected number of secondary infections caused by a primary infection in a fully susceptible population, [12-20]
\item Starting set of infected persons (S) : Number of persons in the population that is an infected person at the start of the simulation, [1-500]
\item Immunity fraction (I) : Fraction of the population that is immune to the disease at the start of the simulation. [0.75, 0.95]
\end{itemize}
For each parameter we used 30 points uniformly chosen in their range and the simulator is run once for each configuration. 
As output parameter, we used the the attack rate, which is measured as the rate of the total number of cases in the population versus the size of the population. 



\paragraph{Symbolic regression configuration}
We run the GP-SR with 30 phases, each consisting of 60 generations of 20 expressions with an initial depth of 3 and maximum depth of 6. The 4 best expressions of each phase are archived.
We compare 3 approaches based on fitness gain and computational cost. Firstly, we run all simulations and use the CSRM tool on the entire simulation dataset. This is the traditional approach where the GP-SR tool is not seeded and so starts a blind search. 
Secondly, we split the data into incremental sections. We start the CSRM tool after 10 configurations have been simulated. The best 4 results are saved to disk and used as seed to model 20 simulated configurations. The results of the 20-point dataset are used to seed for the 30 point SR run. The cost of running the 10 and 20 point runs to use as seed for the 30 point run is similar to the cost of the 30 point run. 
Thirdly, we run the tool on the data from 30 configurations with a double amount of phases. As such, it has the same number of fitness evaluations as the 10-20-30 combination. 
We run the experiment distributed to observe the change in convergence characteristics using the seeds of the 10-20-30 combination to combine the distributed and incremental features of our tool. %LW: rephrase...

%\subsection{Results}
\subsubsection{Fitness improvement}
We compare both seeded runs and the extended run with the 30-point run. In Figure \ref{fig:incrementalgain} we see that the fitness is improved by using the best results of the previous run on a partial data set. We have deliberately split our data set in such a way as to expose a risk here. If we run the tool with 20 datapoints seeded by a run of 10 datapoints, we see that the validated fitness actually decreases compared to a non seeded run. The ratio between new and known data is too large, leading to overfitting. If we seed the best results from the 20-point run into a 30 point configuration we see that both the training and validated fitness values significantly improve. The 30 point run with 60 phases has the same computational cost as the 10-20-30 runs combined, but gains little to nothing in convergence. We see that convergence is slowing, with training fitness improving by a factor of 10 \%, but validation fitness worsens. This is a typical example of overfitting. The combined 10-20-30 run increases validation fitness with a factor of 13\%

\subsubsection{Distributed}
Next we seed a distributed run with the results of the 10/20/30 run and compare the topologies in terms of fitness improvement and speedup. We run the same configuration as before with 25 processes, we use as seeds the 4 best expressions from the 10/20/30 run, and use Tree, Grid, Random and Disconnected topologies. In Figure \ref{fig:usecasedistributed} we compare the gain in fitness on the validation data for the tree, grid and randomstatic topologies compared to the disconnected topology. We can clearly see that the diffusion in the grid topology leads to the highest gain, followed by the tree topology. Interestingly enough, the random topology scored worse than the disconnected topology. This can occur when a local optimum is communicated early to the other processes which then dominates the remainder of the process. The effect on the runtime is measured in Figure \ref{fig:usecasespeedup}. We see that the tree topology has minimal overhead and runs nearly as fast as the disconnected topology where no synchronization or communication overhead is present. The grid topology suffers a 2x performance penalty and the random topology finds the middle ground between the two. During the experiment we observed that the processes in the tree and disconnected topologies varied as much as 4 phases. This is what we expected, in this tree topology the distance between two processes is at most 4 (depth of a 25-node binary tree). This is an important observation, if we increase the number of processes the tree topology will actually scale better. The delay tolerance allows the tree topology this scaling effect.

\begin{figure}
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.8\linewidth]{figures/usecasedistributed.png}
		\caption{Incremental distributed CSRM applied to use case.}
		\label{fig:usecasedistributed}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.8\linewidth]{figures/usecasespeedup.png}
		\caption{Runtime impact of synchronization and communication overhead.}
		\label{fig:usecasespeedup}
    \end{subfigure}
        \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.8\linewidth]{figures/incrementalgain.png}
        \caption{Incremental fitness gain in CSRM.}
        \label{fig:incrementalgain}
    \end{subfigure}
        \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.5\linewidth]{figures/responseR.png}
        \caption{Response of attack rate to R.}
    \end{subfigure}
    \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.5\linewidth]{figures/responseS.png}
        \caption{Response of attack rate to S.}
    \end{subfigure}
        \begin{subfigure}{0.5\textwidth}
        \includegraphics[width=0.5\linewidth]{figures/responseI.png}
        \caption{Response of attack rate to I.}
        \label{fig:usecaseresponseplots}
    \end{subfigure}
    %\caption{Use case : Effect of topology on fitness correlation of distributed processes.}
    %\label{fig:usecasecorrelation}
\end{figure}

We select the best expression returned by the distributed application of CSRM with a tree topology, given its benefits in runtime and scaling. The resulting expression has a fitness value of 0.039 on the full data set. While this value is low, it is still 10 orders of magnitude removed from the optimal. This expression therefore represents an intermediate result and gives us an indication of the value partial results can offer. We use response plots for each parameter in order to isolate the effect each parameter has. We vary each of the parameters while keeping the other two constant. For the constant value we select the midpoint of the range. We then observe the effect on the attack rate. It is important to note that the range of the attack rate is [0,1]. We observe 2 important effects. First, our model produces an attack rate outside of the valid range of [0,1]. There is a scaling factor of 10 between the output of the model and the actual output data from the simulator. This is simply due to the fact that convergence is still in an intermediary phase. An important observation here is that our tool evolves the model based on 30 data points and not the full factorial design. This means that the response plots will use the model to evaluate points that are not necessarily available to our tool to train on. Second, the trend in the response plots is in line with what we expect to see in such a surrogate model. When R0 increases the attack rate increases, which is in line with theoretical and empirical results. A similar trend is visible with the initial number of infected persons, where R0 shows a logarithmic response. Finally, as the immunization fraction increases we see a negative linear response in the attack rate. We have chosen this suboptimal surrogate model to demonstrate that while the exact values of the attack rate are not yet correctly modelled, the expected trends are. This conclusion is vital to justify our incremental approach. We can see that surrogate models will focus on matching the trend first, rather than matching individual points. This is in part due to our usage of the Pearson R correlation coefficent as a basis for the fitness function. 

