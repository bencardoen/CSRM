The reference work \cite{parallelmetaheuristics} provides a broad overview of the challenges and advantages of parallel metaheuristics. An interesting parallel GP-SR implementation \citep{DGPSR} introduces a random islands model where processes are allowed to ignore messages, contrary to our approach. The authors argue that this promotes niching, where 'contamination' of locally (per process) fit individuals could otherwise introduce premature convergence. The advantage of such a system is speedup, since no process ever waits on other processes. Another difference with our approach is the message exchange protocol. 
Whereas we exchange all messages after each generational phase, \citep{DGPSR} interleaves message exchange with computation during a phase. Such a setup allows for a heterogeneous set of processes. 

A different approach is shown in \citep{DFGPSR} where a master slave topology is used in combination with a load balancing algorithm in order to resolve the imbalance between the different slaves executing uneven workloads. The slaves are not separate algorithms: they are assigned a subset of the population and only compute the fitness function. The selection and evolution are performed by the master process. This a a fine grained approach and  offers a speedup compared to a sequential GP-SR implementation, but it does not increase the coverage of the search space. 

In Distributed Genetic Progamming (DGP) \cite{DGP} a ring and torus topology are used. The two-way torus topology is similar to our grid topology. The study finds that sharing of messages is essential to improve convergence but that the communication pattern is largely defined by the problem domain. It concludes that diffusion is a more powerful technique compared to partitioning. 