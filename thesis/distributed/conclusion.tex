We have introduced a distributed SR tool that with a delay tolerance mechanism that mitigates load imbalance between processes. We compared three representative topologies in terms of convergence rate and speedup. The tree topology can be used as an approximation for the grid topology with near linear speedup and offers a process a delay tolerance equal to the distance between dependent processes. This feature allows the tree topology to scale better when the process set is larger. The distributed processes approximate K fold cross validation (KCV) in order to avoid overfitted solutions without the high computational cost of KCV. Our modular architecture allows it to be extended with new topologies, policies, and optimization algorithms. 
In the use case we demonstrated how our tool can be used to derive a surrogate model for a simulator in parallel without waiting for the simulator to complete all results. In particular we looked at the interaction between simulator and regression tool and showed that our incremental support allowed for improvements in fitness and predictive value of the final model. A feedback loop between practitioner, simulator and regression tool offers savings in time that increase with the computational cost of the simulator while yielding valuable insights that can be used during the experiment to adapt the design. The use case demonstrated that intermediate solutions are able to approximate the final model's characteristics even at a significant distance from the actual solution, validating our incremental approach. The distributed results of the use case were in line with the results of the benchmarks, the grid topology obtained the highest quality solution at the lowest speedup. The tree topology achieved a near linear speedup at the cost of a lower quality solution. The random topology demonstrated that the incremental approach can lead to overfitting in a distributed setting. 
Future work can take any of three directions. First our distributed architecture allows for a each process to use a different metaheuristic, creating a heterogeneous set of communicating algorithms. A cooperative set of optimizations algorithms could offer an optimal solution for all problem instances by balancing the disadvantages and advantages of each algorithm. 
Second, the tool can easily be extended with new topologies and spreading policies to further investigate their effects on convergence and accuracy. Lastly, we can approximate incremental design of experiment by making use of the collapsing property of latin hypercubes. By reducing the number of parameters and fixing the other values, we avoid the naive linear division approach we thus far have used in seeding the tool and possibly maintain the space filling characteristics of the LHD.
