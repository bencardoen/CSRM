An open source \href{https://bitbucket.org/bcardoen/csrm}{repository} holds the project's source code, benchmark scripts, analysis code and plots. Additional results, left out here due to space constraints are covered in \href{https://bitbucket.org/bcardoen/csrm/src/9de4b990ce27bbaeb885203f82a76635d8d92473/thesis/thesis/MsCThesisBenCardoen.pdf?at=master&fileviewer=file-view-default}{work}. The project dependencies are minimal making the project portable across any system with Python3, pip as an installation manager and MPI.

The experiments were performed on an Intel Xeon E5 2697 processor with 64GB RAM, with Ubuntu 16.04 LTS.  The experiments use a fixed seed in order to guarantee reproducibility. Where relevant we specify the parameter configuration.
 
\paragraph{Benchmark problems}
Recent work on the convergence of GP-based SR \cite{SRAccur, SRBaseline} featured a set of benchmarks that pose convergence problems for SR implementations. 
These 15 benchmarks use at most five features and are non linear arithmetic expressions using standard base functions : (sin, cos, tan(h), log,$a^x$, /, *, modulo, abs, min, max, +, -). CSRM does not know which features are used, making the problem even harder. In other words it only assumes each problem is a function of 5 features which may or may not influence the expected outcome, testing the robustness of the algorithm.

\paragraph{Experiment setup}
Each process has a population of 20, initial depth of 4, max depth of 8, executes 20 phases of 20 generations each, with an archivesize of 20. Per phase the 4 best expressions are archived, the spreading policy distributes the best expressions over the communication links. The benchmark functions have at most 5 features, each with 20 sample points in the range [1,5]. The Grid and Tree topology will have single expression per link, the Random topology will have 2 per link. 25 processes are used, resulting in respectively 400, 15 ,50 being sent per phase. The random topology in this case contains 2 cliques of cycles.

When the experiment ends the best 20 expressions from all processes are collected and scored. We measure best fitness on the training data, and best fitness on the validated data. 
Finally we record the mean fitness values of the best 5 expressions, both on the training and validation data. The mean is restricted to the upper quarter of the population specifically to measure how the best expressions are distributed. This measure records the convergence more accurately as the fittest expressions drive the convergence rate. 

Fitness values fluctuate strongly between across test problems and topologies. We apply a negative logarithmic scale : $f_t = -\log_{10}(f)$ where f is either the best fitness value or the mean. Then we scale the results relative to the values obtained for the tree topology in order to measure relative gain or loss in orders of magnitude.

\subsubsection{Results}
\paragraph{Convergence}
\begin{figure*}
    \centering
    \begin{subfigure}{0.5\textwidth}
    \centering
        \includegraphics[width=0.5\linewidth]{figures/distributedbesttraining.png}
        \caption{Relative gain in best fitness of training data}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
    \centering
        \includegraphics[width=0.5\linewidth]{figures/distributedbestvalidated.png}
        \caption{Relative gain in best fitness on full data.}
    \end{subfigure}
        \begin{subfigure}{0.5\textwidth}
    \centering
        \includegraphics[width=0.5\linewidth]{figures/distributedmeantraining.png}
        \caption{Relative gain in mean fitness on training data.}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
    \centering
        \includegraphics[width=0.5\linewidth]{figures/distributedmeanvalidated.png}
        \caption{Relative gain in mean fitness on full data.}
    \end{subfigure}
    \caption{Convergence differences between topologies.}
    \label{fig:distributedresults}
\end{figure*}
\begin{figure}
	\begin{subfigure}{0.5\textwidth}\label{fig:csrmkfold}
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/validationcsrm.png}
    \caption{Approximation of k fold cross validation with parallel processes, k = 4,  r = $\frac{3}{4}$.}
    \end{subfigure}
	\begin{subfigure}{0.5\textwidth}    \label{fig:kfold}

    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/kfold.png}
    \caption{Visualization of k fold cross validation with k = 4.}
%    \label{fig:kfold}
    \end{subfigure}%
%    \caption{Topologies in CSRM.}
    \label{fig:ckfold}
 \end{figure}

In Figure \ref{fig:distributedresults} we see how the topology affects convergence. The first observation we make is that the first 5 benchmarks, with exception of the second, all have identical values for best fitness on training and validation data. The processes converged to zero fitness values for these problems, hence the identical results. The training fitness results in Figure \ref{fig:distributedresults}a indicate that the grid and random topology have superior convergence characteristics compared to the tree topology, with grid outperforming random on several benchmarks. When we look at the fitness values on the validation data in Figure \ref{fig:distributedresults}b we see a more nuanced result. Overall the grid topology is the best choice, the random topology has worse results for problems 11 and 12. Next we look at the mean fitness values on training and validation data. Interestingly enough for problem 0 both random and grid score far worse than the tree topology. Overall the grid topology is still better for most problems, with the exception of problem 7. Note the similarity in pattern in the results here between training and validation data indicating that the predictive capability of the results is still good. If overfitting would have taken place we would see a reverse pattern in the results for the validation data.

\paragraph{Measuring Overhead}
Cycles in the topology lead to excessive synchronization and even serialization. We measure the mean execution time for benchmark 6. The convergence characteristics using the three topologies differ significantly making this a good testcase. The processes will communicate 25 times. If the runtime of a single phase is too long, communication overhead becomes hard to measure. If it is too short, overhead dominates the entire runtime. This second case is one we should try to avoid, it will unfairly penalize topologies with cycles forcing them to serialize. The runtime of a phase is dependent on the generations, population and depth ranges of the expressions. Ideally we would like for a practitioner to choose these parameters based on the problem at hand and not be constrained by synchronization considerations. To compare the three topologies, we use the disconnected or 'none' topology as a reference point, as it has zero synchronization overhead and has an ideal speedup of n, where n is the processcount. From the synchronization overhead we can then derive the speedup each of the topologies is able to offer. In practice even the 'none' topology will have some synchronization overhead, as the root process has to collect all results.
\begin{figure*}
    \centering
    \begin{subfigure}{0.5\textwidth}
    \centering
        \includegraphics[width=0.5\linewidth]{figures/distributeddelaymean.png}
        \caption{Mean synchronization delay factor.}
    \end{subfigure}%
    \begin{subfigure}{0.5\textwidth}
    \centering
        \includegraphics[width=0.5\linewidth]{figures/distributeddelaysd.png}
        \caption{Standard deviation of synchronization delay factor.}
    \end{subfigure}
    \caption{Synchronization overhead introduced by topologies.}
    \label{fig:distributeddelayresults}
    \end{figure*}
In Figure \ref{fig:distributeddelayresults} we see that the tree topology has near zero delay caused by the synchronization. This is due to the delay tolerance we have built in in our implementation. The random topology has a mean delay factor of 1.3, the grid topology  has a mean delay factor of nearly 2. This is easily translated in terms of speedup. A tree topology will have near linear speedup, a grid will have a speedup roughly half of that value and a random topology will have a speedup bracketed between those two. The standard deviation for the tree topology is significantly smaller indicating that a tree topology will have a far more predictable speedup.