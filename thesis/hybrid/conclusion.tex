
We have implemented a baseline GP SR tool based on a tree representation that allows for inspection of the convergence process through extensive statistics and visualization. We implemented the classical mutation and crossover operators and applied a cooling schedule to mutation that saves computational cost. 
The constant generation and optimization problem was tackled using a 2 pronged approach. We apply constant folding to reduce the size of the expression trees. This approach, although it can slow the generation of constants, is vital for the second stage of our approach. We hybridize GP with 3 continuous optimization algorithms and compare the results. We find that, while in general convergence improves, the application of the continuous optimizer should be chosen such that overfitting is not introduced.
As expected from the NFL theorem no single algorithm was optimal for all problem instances, validating both the test problems we used and the implementation of the algorithm.
Our tool can be run distributed with a delay tolerance mechanism that mitigates load imbalance between processes. We compared three representative topologies in terms of convergence rate and speedup. The tree topology can be used as an approximation for the grid topology with near linear speedup. The tree topology offers a process a delay tolerance equal to the distance between dependent processes. This feature allows the tree topology to scale better when the process set is larger. 
The distributed processes approximate K fold cross validation (KCV) in order to avoid overfitted solutions without the high computational cost of KCV. 
The tool's modular architecture allows it to be extended with new topologies, policies, and even algorithms. 
As a use case we demonstrated how our tool can be used to derive a surrogate model for a simulator. In particular we looked at the interaction between simulator and regression tool and showed that our incremental support allowed for improvements in fitness and predictive value of the final model. The incremental support allows the tool to run in parallel with the simulator. A feedback loop between practitioner, simulator and regression tool offers savings in time that increase with the computational cost of the simulator while yielding valuable insights that can be used during the experiment to adapt the design.
Applying the constant optimizers in the use case demonstrated the risk of overfitting when combined with the incremental approach. 
The distributed results of the use case were in line with the results of the benchmarks, the grid topology obtained the highest quality solution at the lowest speedup. The tree topology achieved a near linear speedup at the cost of a lower quality solution. The random topology demonstrated that the incremental approach can lead to overfitting in a distributed setting.