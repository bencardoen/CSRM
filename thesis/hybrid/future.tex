\paragraph{Extending constant optimization}
\subparagraph{Linear weight optimization}
The constant optimization step applied in our tool has been limited to simple constants in the expression. The tree representing the expression stores a hidden constant for each node that can act as linear weights. We can extend the constant optimization step to include these constants. The advantage is that the expression can be optimized to a greater extent. The disadvantage is the high increase in computational cost. Each constant represents a dimension for the constant optimizer. From our discussion we know that a high dimensionality has a serious impact on the complexity of the optimization step. 
\subparagraph{Extending folding}
Using the linear weights representation we could further simplify trees when applying constant folding. The following simple expression
\[
f(x) = \sin( \pi \frac{\tan(x)}{2})
\]
is represented using a tree with 7 nodes. If we extract $\frac{\pi}{2}$ as a linear weight for the $\tan$ node the tree is reduced to three nodes. The expression is invariant, but the representation is far more compact.
\[
f(x) = \sin( \frac{\pi}{2} \tan(x))
\]
Detecting and folding such cases is non trivial for more complex expressions.

\paragraph{Distributed set of heterogeneous optimizers}
We can replace GP with several other combinatorial optimization algorithms and compare convergence. From recent literature we know that ACO, GE and ABC have been used. Using our distributed architecture it would be possible to give each process a different optimization algorithm. This has two advantages. First, it allows for comparison of different optimization algorithms within the same framework. Second, it would make the SR tool more robust. Each optimization algorithm has its strengths and weaknesses. We know from the NFL theorem that no optimization algorithm is optimal for all optimization problem instances. A cooperative set of optimizations algorithms could offer an optimal solution for all problem instances by balancing the disadvantages and advantages of each algorithm. Such a heterogeneous set of optimization algorithms is difficult to implement. Each optimization algorithm has its own problem representation (e.g. GP's tree, DE's vector). Communication requires a shared representation which can prove to be a significant technical challenge. Finally the variation in runtime for each algorithm is likely high, leading to synchronization issues.

\paragraph{Base functions}
In this work we have seen how great the impact is from invalid expression on the runtime of the algorithm. If we use a set of base functions where the domain is identical for each, for example the Chebyshev polynomials, and rescale our input set then we could largely avoid the initialization issue.
A domain expert should be able to give hints to the tool specifying which base functions are expected to be used. If this is uncertain a weighted set of functons could be introduced. If a sinoid is expected, but other base functions cannot be excluded, we could bias the functionset by introducing weights steering the selection of base functions. This functionality is partially present in the current state of the tool.

\paragraph{Policies}
This work can be extended by several policies. The spreading policies in the topology can be extended with random sampling, new trends in archiving can be applied to the algorithm and the mutation and crossover operators can be similarly extended. 

\paragraph{Topologies}
The inverted tree topology, where the root is a sink and leaves are sources, is an interesting alternative to the original tree. Future work could evaluate other communication strategies such as random sampling. A random tree topology could offer a balance between convergence and speedup. Several approaches are possible, we could use a static tree topology where a process decides at runtime which child to send to. Or we could generate a random tree at each iteration. This approach would aim to combine the advantages of a stochastic approach with the speedup gains of the tree structure itself. Such a tree could lead to the introduction of synchronization at each communication cycle.

\paragraph{Hyperheuristics}
Our distributed SR algorithms has a large parameter space, most of which influences the convergence characteristics. Their optimal values can be problem dependent, correlated to each other and are in general unknown. Optimizing these values requires a new optimization algorithm. Another alternative is a self optimizing variant that uses statistics collected at runtime to modify the parameters in order to find more optimal values.

\paragraph{Random distributions}
The choice of random distribution in a stochastic algorithm such as most metaheuristics has a significant impact on the convergence characteristics. From generating initial values to perturbing known solutions, selecting targets for evolutionary operators, selecting communication partners and so on. The distribution used will have a definite effect on the exploration/exploitation balance in the algorithm. Recent work uses new distributions such as Levy \citep{ABCLevy} to improve convergence of metaheuristcs. This remains an interesting and open subproblem for symbolic regression. 

\paragraph{Incremental DOE}
Dividing the DOE generated input points into sections and using them in the regression tool can lead to issues regarding the structural properties of the design. While our results indicate that the model obtained from an incremental run has a higher quality compared to that  of a unseeded run, this does not exclude the possibility that the seed we used corresponds with a biased coverage of the parameter space. An alternative approach would be to increment not datapoints but parameters. The LHD maintains its structural properties when parameters collapse or are removed. While we could run the SR tool with incremental seeds where parameters are added to the dataset, the simulator would have to be assigned default values for those parameters. This approach has an interesting analogy with a suggested technique in dealing with multiobjective genetic programming. While Pareto optimality and a linear weighted fitness function are the two most common approaches in dealing with multiobjective metaheuristics, there is a hierarchical approach that can be used instead. With k objectives, the algorithm introduces an ordering in the objectives and optimizes in stages. In the first stage the fitness function use the first ordered objective. The results of this stage are then seeded into the next stage, where the fitness function targets the second objective and so on. A strict order between objectives in not necessary for this approach though recommended. The algorithm is using a set of k fitness functions and may not find the global optimum that a Pareto front or linear weighted fitness function would find, depending on the correlation between the objectives.
