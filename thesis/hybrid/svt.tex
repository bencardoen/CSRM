%We have implemented a baseline GP SR tool based on a tree representation that allows for inspection of the convergence process through extensive statistics and visualization. We implemented the classical mutation and crossover operators and applied a cooling schedule to mutation that saves computational cost. 
%The constant generation and optimization problem was tackled using a 2 pronged approach. We apply constant folding to reduce the size of the expression trees. This approach, although it can slow the generation of constants, is vital for the second stage of our approach. We hybridize GP with 3 continuous optimization algorithms and compare the results. We find that, while in general convergence improves, the application of the continuous optimizer should be chosen such that overfitting is not introduced.
%As expected from the NFL theorem no single algorithm was optimal for all problem instances, validating both the test problems we used and the implementation of the algorithm.
%Our tool can be run distributed with a delay tolerance mechanism that mitigates load imbalance between processes. We compared three representative topologies in terms of convergence rate and speedup. The tree topology can be used as an approximation for the grid topology with near linear speedup. The tree topology offers a process a delay tolerance equal to the distance between dependent processes. This feature allows the tree topology to scale better when the process set is larger. 
%The distributed processes approximate K fold cross validation (KCV) in order to avoid overfitted solutions without the high computational cost of KCV. 
%The tool's modular architecture allows it to be extended with new topologies, policies, and even algorithms. 
%In the use case we demonstrated how our tool can be used to derive a surrogate model for a simulator. In particular we looked at the interaction between simulator and regression tool and showed that our incremental support allowed for improvements in fitness and predictive value of the final model. The incremental support allows the tool to run in parallel with the simulator. A feedback loop between practitioner, simulator and regression tool offers savings in time that increase with the computational cost of the simulator while yielding valuable insights that can be used during the experiment to adapt the design.
%Applying the constant optimizers in the use case demonstrated the risk of overfitting when combined with the incremental approach. 
%The distributed results of the use case were in line with the results of the benchmarks, the grid topology obtained the highest quality solution at the lowest speedup. The tree topology achieved a near linear speedup at the cost of a lower quality solution. The random topology demonstrated that the incremental approach can lead to overfitting in a distributed setting.
In dit werk bekijken we de convergentie karakteristieken van symbolische regressie (SR) gebruik makend van metaheuristieken. In de context van computationeel intensieve simulaties is het essentieel een surrogaat model te bekomen dat het onderliggend process benadert. Symbolische regressie is een methode die dit mogelijk maakt door een analytische expressie te fitten aan de simulatie data. Het biedt een model aan dat, in tegenstelling tot andere technieken, inzicht verschaft in de constructie van het model en de correlatie tussen de parameters die het model vormen. De convergentie karakteristieken van symbolische regressie zijn nog een open probleem.
We implementeren SR aan de hand van genetisch programmeren (GP). We analyseren de problemen die zich stellen bij de convergentie van SR en richten ons specifiek op twee aspecten : constante optimalisatie en parallelisatie. Voor het eerste probleem passen we constant folding toe als een precursor stap tot hybridizering van GP met 3 representatieve continue metaheuristieken. We analyseren de resultaten in de dimensies van kwaliteit van het model en computationele cost aan de hand van een set van benchmarks geintroduceerd in het veld die specifiek gericht zijn op dit probleem. We introduceren een cooling schedule voor de mutatie operator in GP en bekijken de computationele winst ervan. 
We paralleliseren SR en kijken naar het effect dat communicatie topologiëen hebben op de convergentie karakteristieken en overhead uitgedrukt in synchronisatie kost. 
We introduceren een hiërarchische topologie die ten koste van diffusie een quasi lineaire speedup behaalt. Deze topologie schaalt beter naarmate het aantal processen toeneemt. We ondersteunen incrementeel gebruik van partiële resultaten, wat een feedback loop mogelijk maakt tussen gebruiker, simulator en regressie tool. We passen deze aanpak toe op een simulatie use case van mazelen in de stad Antwerpen en bekijken hoe onze aanpak kan leiden tot een reductie in tijd voor de gebruiker en een toename in kwaliteit van het resulterende model.