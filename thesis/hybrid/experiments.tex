% USE gp grid parameters
% Experiments
% shared experiments
\subsection{Benchmark problems}
Recent work on the convergence of GP-based SR \cite{SRAccur, SRBaseline} featured a set of benchmark problems that pose convergence problems for SR implementations. We reuse these problems in our work in order to study convergence of CSRM's implementation.
\subsubsection{Problems}
These problems use at most five features, when present to CSRM we do not give the algorithm this knowledge. In other words it assumes each problem is a function of 5 features which may or may not influence the expected outcome. This is an extra test in robustness for the algorithm, while also testing the algorithm's capability as a classifier.
\[
1.57 + (24.3*x_3)\]
\[0.23+14.2*\frac{x_3+x_1}{3.0*x_4}
\]
\[
-5.41 + 4.9* ( \frac{x_3-x_0 +  \frac{x_1}{x_4} } {3*x_4} )
\] 
\[-2.3 + 0.13*\sin(x_2)\]
\[3.0 + (2.13 * ln(x_4))\]
\[1.3 + 0.13* \sqrt{x_0}\]
\[213.80940889 - 213.80940889*e^{-0.54723748542*x_0}\]
\[6.87+11*\sqrt{7.23*x_0*x_3*x_4}\]
\[\frac{\sqrt{x_0}}{\ln(x_1)} *\frac{e^{x_2}}{x_3 ^ 2}\]
\[ 0.81 + 24.3 * \frac{ 2.0*x_1+3.0*x_2^2} {4.0*x_3^3 + 5.0*x_4^4}\]
\[6.87+ 11* \cos(7.23*x_0^3)\]
\[2.0 - 2.1 * \cos(9.8*x_0) * \sin(1.3*x_4)\]
\[32-3.0*  \frac{\tan(x_0)}{\tan(x_1)} *  \frac{tan(x_2)} {\tan(x_3)} \]
\[22 - 4.2*((\cos(x_0)-\tan(x_1))*\frac{\tanh(x_2)}{\sin(x_3)}\]
\[12.0 - 6.0* \frac{\tan(x_0)}{e^{x_1}} * (\ln(x_2)-\tan(x_3) ) \]
                    

\subsection{Operators}
\input{sharedexperiments.tex}
% Show the effect of cooling
% Show the effect of depth sensitive

% Exclusive experiments
\subsection{Constant Folding}
\subsubsection{Savings}
% Show effect of constant folding savings
\subsubsection{Effect on convergence}
% Show fitness effect of constant folding

\subsection{Constant optimization}
We look at the effect constant optimization using different algorithms has on different configurations of the tool. The measures used in the comparison are best fitness on training and test data, mean fitness on training and test data, and optimization cost.

\subsubsection{Test problem}
To verify our implementation for the optimizers we use a simple test problem and observe for each optimizer if it is able to optimize this instance to a known optimal value.
\[
f(x_0, x_1, x_2) = 1 + x_1 * \sin (5+x_2) * x_0 + (17 + \sin (233+9))
\]
We give each optimizer a population of 50, 50 iterations and compare the results for 10 runs, displaying best value obtained, mean, and standard deviation of the fitness values compared to the known best value.
\paragraph{Best fitness}
In Figure \ref{fig:testproblembest} we see that DE outperforms PSO and ABC with several orders of magnitude. The best fitness value obtained was 2.22 e-16. As smaller but significant difference is present between PSO and ABC. This result is somewhat surprising given that fact that ABC is allowed to perform more evaluations in its configuration. From our previous discussion \ref{psocost},\ref{decost},\ref{abccost} we can conclude that for this test problem DE is clearly preferable as it obtains the best result at minimum cost. ABC has almost double the cost compared to PSO and DE, with PSO and DE having an equal cost in evaluations. The results on this testproblem do not necessarily mean that in the application of the three optimizers the results will be identical. Here we have a known optimal solution and want to observe how fast the optimizers converge to it. When we optimize evolved expressions we do not know what the optimal solution is. The problem statement is different, and so the convergence behavior is likely to differ as well. In Figures \ref{fig:testproblemmean} and \ref{fig:testproblemsd} we see that both the mean and standard deviation follow the same pattern as seen for the minimum fitness value with DE leading the others by several orders of magnitude. With all three distributions behaving similarly, this result provides a more solid foundation for our conclusions that for this problem DE is indeed the better optimizer.
\begin{figure}
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/testproblem_bestfitness.png}
    \caption{Logarithmic value of best fitness for each optimizer.}
    \label{fig:testproblembest}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/testproblem_meanfitness.png}
    \caption{Logarithmic scaled mean fitness for each optimizer.}
    \label{fig:testproblemmean}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/testproblem_sdfitness.png}
    \caption{Logarithmic scaled standard deviation fitness for each optimizer.}
    \label{fig:testproblemsd}
\end{figure}

\subsubsection{Optimizer experiments setup}
We test the 15 expressions with the following configuration:
\begin{itemize}
\item population : 20
\item minimum depth : 4
\item maximum depth : 10
\item phases : (2, 5, 10)
\item generations : 20
\item datapoints : 20
\item range : [1,5]
\item features : 5
\item archivesize : 20
\item expressions to archive per phase : 4
\item optimization strategy : optimize expressions archived at end of phase
\end{itemize}
\subsubsection{Measures}
We compare the relative gain in fitness compared to not using an optimizer for all expressions. 
In other words, if $m_n$ is a measure obtained by the algorithm without the optimizer, and $m_a$ the same measure with the optimizer, we then define the relative gain as :
\[
g_{ma} = \frac{m_n}{m_a}
\]
If $m_a$ is zero, we use $-log_{10}(m_n)$ to represent the gain. If both are zero, the gain is obviously 1. A value of g $>$ 1 indicates the ratio with which the optimizer improves the result. A g value $<$ 1 indicates a regression.
These 15 functions have wildly varying convergence behavior. In order to make sense of the data, we then apply a log scale :
\[
g_{lma} = - \log_{10}(g_{ma})
\]
A value of $g_{lma} > 0 $ indicates improvement, with the units transformed to orders of magnitude. A zero value indicates no improvement is registered, and negative values indicate regression. 
\subsubsection{2 Phases}
In Figure \ref{fig:fig2phasetrainminfitness} we see the performance of the algorithms on training data. 
We see that for the training fitness data the improvements are significant, with ABC scoring an increase of 2.5 orders of magnitude for problem 6. For the other problems the increase is still large, especially given that our fitness function has a range of [0,1].
We also observe the significant regression for problem 6. This is likely caused due to overfitting. The algorithm in question (DE) optimizes the 4 best candidates of the last phase (1), but it is possible that these optimized expressions actually form a local optimum. By archiving these the convergence of the algorithm is hindered in the next phase. Note that DE allows equality updates, where expressions with the same fitness values are accepted as better. The same behavior occurs in a far less significant effect for expressions 7 and 9. A second explanation is our implementation of the population. The algorithm enforces distinct fitness values for all expressions. In an edge case it is possible that these optimized samples form a barrier, preventing other expressions from evolving past them. The optimized expressions in effect trap the rest of the population, which given our low generation count can explain this behavior.
\begin{figure}
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/hybrid_phases2_mintrainfitness.png}
    \caption{Logarithmic scaled gain in minimum fitness.}
    \label{fig:fig2phasetrainminfitness}
\end{figure}
\begin{figure}
    \centering
    \includegraphics[width=\textwidth,height=\textheight,keepaspectratio]{figures/hybrid_phases2_minfullfitness.png}
    \caption{Logarithmic scaled gain in minimum fitness.}
    \label{fig:fig2phasefullminfitness}
\end{figure}
\begin{landscape}
\begin{table}[]
\centering
\caption{Relative Gain in minimum fitness on training data after 2 phases.}
\label{table:2phasemintrain}
\begin{adjustbox}{width=1.7\textwidth}
\begin{tabular}{lllllllllllllllll}
          &           &           &           &           &           &           &           &           &           &           &           &           &           &           &           &  \\
           & 0         & 1         & 2         & 3         & 4         & 5         & 6         & 7         & 8         & 9         & 10        & 11        & 12        & 13        & 14        &  \\
ABC                 & 1.000e+00 & 1.000e+00 & 1.295e+00 & 1.848e+01 & 1.000e+00 & 1.000e+00 & 4.253e+02 & 1.030e+00 & 2.897e+00 & 9.615e-01 & 1.415e+00 & 1.207e+00 & 1.404e+00 & 1.000e+00 & 9.970e-01 &  \\
DE                  & 1.000e+00 & 1.536e+00 & 1.163e+00 & 2.923e+00 & 1.000e+00 & 1.000e+00 & 2.584e-01 & 1.526e+00 & 2.294e+00 & 8.972e-01 & 1.210e+00 & 1.327e+00 & 9.397e-01 & 1.536e+00 & 9.960e-01 &  \\
PSO                 & 1.000e+00 & 1.839e+00 & 1.169e+00 & 1.150e+00 & 1.000e+00 & 1.000e+00 & 1.000e+00 & 8.356e-01 & 2.947e+00 & 8.971e-01 & 1.226e+00 & 1.247e+00 & 1.096e+00 & 1.000e+00 & 1.172e+00 &  \\

\end{tabular}
\end{adjustbox}
\end{table}

\begin{table}[]
\centering
\caption{Gain in minimum fitness on full data after 2 phases.}
\label{table:2phaseminfull}
\begin{adjustbox}{width=1.7\textwidth}
\begin{tabular}{lllllllllllllllll}
         &           &           &           &           &           &           &           &           &           &           &           &           &           &           &           &  \\
         & 0         & 1         & 2         & 3         & 4         & 5         & 6         & 7         & 8         & 9         & 10        & 11        & 12        & 13        & 14        &  \\
ABC                 & 1.000e+00 & 1.000e+00 & 1.122e+00 & 1.865e+01 & 1.000e+00 & 1.000e+00 & 3.831e+02 & 1.034e+00 & 2.691e+00 & 1.016e+00 & 8.528e-01 & 1.051e+00 & 6.169e-01 & 1.000e+00 & 9.938e-01 &  \\
DE                  & 1.000e+00 & 1.597e+00 & 1.039e+00 & 2.757e+00 & 1.565e+01 & 1.000e+00 & 2.233e-01 & 1.674e+00 & 2.004e+00 & 9.617e-01 & 9.337e-01 & 1.103e+00 & 9.584e-01 & 1.597e+00 & 9.970e-01 &  \\
PSO                 & 1.000e+00 & 3.098e+00 & 9.915e-01 & 8.538e-01 & 1.000e+00 & 1.000e+00 & 1.000e+00 & 7.145e-01 & 2.586e+00 & 9.617e-01 & 1.274e+00 & 1.067e+00 & 1.055e+00 & 1.000e+00 & 1.069e+00 &  \\
\end{tabular}
\end{adjustbox}
\end{table}

\begin{table}[]
\centering
\caption{Relative gain in mean fitness of 5 fittest expressions on training data after 2 phases.}
\label{table:2phasemeantrain}
\begin{adjustbox}{width=1.7\textwidth}
\begin{tabular}{lllllllllllllllll}
 &           &           &           &           &           &           &           &           &           &           &           &           &           &           &           &  \\
           & 0         & 1         & 2         & 3         & 4         & 5         & 6         & 7         & 8         & 9         & 10        & 11        & 12        & 13        & 14        &  \\
ABC                 & 2.064e+01 & 3.632e+00 & 1.536e+00 & 8.774e-01 & 1.788e+00 & 1.096e+00 & 5.726e+00 & 1.173e+00 & 2.348e+00 & 9.209e-01 & 1.163e+00 & 1.280e+00 & 1.151e+00 & 3.632e+00 & 9.300e-01 &  \\
DE                  & 1.117e+01 & 5.624e+00 & 1.277e+00 & 1.696e+00 & 2.468e+00 & 8.307e-01 & 3.333e-01 & 9.953e-01 & 2.249e+00 & 1.038e+00 & 1.067e+00 & 1.305e+00 & 9.416e-01 & 5.624e+00 & 9.302e-01 &  \\
PSO                 & 7.494e+03 & 6.977e+00 & 1.225e+00 & 1.091e+00 & 3.335e+00 & 1.461e+00 & 1.154e+00 & 1.118e+00 & 1.300e+00 & 8.794e-01 & 1.212e+00 & 1.559e+00 & 1.041e+00 & 3.632e+00 & 9.242e-01 &  \\

\end{tabular}
\end{adjustbox}
\end{table}


\begin{table}[]
\centering
\caption{Relative gain in mean fitness of 5 fittest expressions on full data after 2 phases.}
\label{table:2phasemeanfull}
\begin{adjustbox}{width=1.7\textwidth}
\begin{tabular}{lllllllllllllllll}
    &           &           &           &           &           &           &           &           &           &           &           &           &           &           &           &  \\
    & 0         & 1         & 2         & 3         & 4         & 5         & 6         & 7         & 8         & 9         & 10        & 11        & 12        & 13        & 14        &  \\
ABC                 & 2.048e+01 & 2.672e+00 & 1.487e+00 & 9.516e-01 & 1.709e+00 & 1.021e+00 & 6.217e+00 & 1.093e+00 & 2.589e+00 & 9.346e-01 & 8.686e-01 & 1.126e+00 & 9.308e-01 & 2.672e+00 & 9.816e-01 &  \\
DE                  & 1.213e+01 & 3.687e+00 & 1.244e+00 & 1.997e+00 & 2.324e+00 & 8.352e-01 & 3.572e-01 & 9.731e-01 & 2.288e+00 & 1.009e+00 & 9.496e-01 & 1.616e+00 & 9.641e-01 & 3.687e+00 & 9.668e-01 &  \\
PSO                 & 8.382e+03 & 8.286e+00 & 1.204e+00 & 1.071e+00 & 3.111e+00 & 1.362e+00 & 1.219e+00 & 9.817e-01 & 1.411e+00 & 8.939e-01 & 1.059e+00 & 1.698e+00 & 1.018e+00 & 2.672e+00 & 9.840e-01 & 

\end{tabular}
\end{adjustbox}
\end{table}

\end{landscape}



\subsubsection{5 Phases}
\paragraph{Fitness}
\paragraph{Cost}

\subsubsection{10 Phases}
\paragraph{Fitness}
\paragraph{Cost}


\subsection{Conclusion}
% Which algorithm is 'better' and how do you define better ?
% When and why do they fail ?
% Add section about overfitting, and explanation