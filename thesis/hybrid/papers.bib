
@InProceedings{PSOParameter,
   author =       {James Kennedy and Russell C. Eberhart},
   title =        {Particle swarm optimization},
   booktitle =    {Proceedings of the 1995 IEEE International Conference on Neural Networks},
   keywords  =    {Particle Swarm},  
   pages     =    {1942--1948},
   volume    =    {4},
   address   =    {Perth, Australia, IEEE Service Center, Piscataway, NJ},
   year = {1995}
 }
 
@InProceedings{PSOInertiaShi, 
  author = {R. C. Eberhart and Y. Shi}, 
  title = {Comparing Inertia Weights and Constriction Factors in Particle Swarm Optimization}, 
  booktitle = {Proc.{} of the 2000 {C}ongress on {E}volutionary {C}omputation}, 
  pages = {84--88}, 
  year = {2000}, 
  address = {Piscataway, NJ}, 
  publisher = {IEEE Service Center} 
} 

@incollection{ffx,
	series = {Genetic and {Evolutionary} {Computation}},
	title = {{FFX}: {Fast}, {Scalable}, {Deterministic} {Symbolic} {Regression} {Technology}},
	copyright = {©2011 Springer Science+Business Media, LLC},
	isbn = {978-1-4614-1769-9 978-1-4614-1770-5},
	shorttitle = {{FFX}},
	url = {http://link.springer.com/chapter/10.1007/978-1-4614-1770-5_13},
	abstract = {Symbolic regression is a common application for genetic programming (GP). This paper presents a new non-evolutionary technique for symbolic regression that, compared to competent GP approaches on real-world problems, is orders of magnitude faster (taking just seconds), returns simpler models, has comparable or better prediction on unseen data, and converges reliably and deterministically. I dub the approach FFX, for Fast Function Extraction. FFX uses a recentlydeveloped machine learning technique, pathwise regularized learning, to rapidly prune a huge set of candidate basis functions down to compact models. FFX is verified on a broad set of real-world problems having 13 to 1468 input variables, outperforming GP as well as several state-of-the-art regression techniques.},
	language = {en},
	urldate = {2016-08-15},
	booktitle = {Genetic {Programming} {Theory} and {Practice} {IX}},
	publisher = {Springer New York},
	author = {McConaghy, Trent},
	editor = {Riolo, Rick and Vladislavleva, Ekaterina and Moore, Jason H.},
	year = {2011},
	note = {DOI: 10.1007/978-1-4614-1770-5\_13},
	keywords = {Algorithm Analysis and Problem Complexity, Artificial Intelligence (incl. Robotics), elastic net, genetic programming, pathwise, integrated circuits, lasso, machine learning, Programming Techniques, real-world problems, regularization, ridge regression, symbolic regression, technology, Theory of Computation},
	pages = {235--260},
	file = {Snapshot:/home/bcardoen/.mozilla/firefox/un9nfpe4.default/zotero/storage/KNI9QUG8/10.html:text/html}
}

@article{ACO,
 author = {Dorigo, M. and Birattari, M. and Stutzle, T.},
 title = {Ant Colony Optimization},
 journal = {Comp. Intell. Mag.},
 issue_date = {November 2006},
 volume = {1},
 number = {4},
 month = nov,
 year = {2006},
 issn = {1556-603X},
 pages = {28--39},
 numpages = {12},
 url = {http://dx.doi.org/10.1109/MCI.2006.329691},
 doi = {10.1109/MCI.2006.329691},
 acmid = {2209187},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
} 

@book{GP,
 author = {Koza, John R.},
 title = {Genetic Programming: On the Programming of Computers by Means of Natural Selection},
 year = {1992},
 isbn = {0-262-11170-5},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@article{NFL,
 author = {Wolpert, D. H. and Macready, W. G.},
 title = {No Free Lunch Theorems for Optimization},
 journal = {Trans. Evol. Comp},
 issue_date = {April 1997},
 volume = {1},
 number = {1},
 month = apr,
 year = {1997},
 issn = {1089-778X},
 pages = {67--82},
 numpages = {16},
 url = {http://dx.doi.org/10.1109/4235.585893},
 doi = {10.1109/4235.585893},
 acmid = {2221408},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
} 

@inproceedings{HyperNFL,
 author = {Poli, Riccardo and Graff, Mario},
 title = {There Is a Free Lunch for Hyper-Heuristics, Genetic Programming and Computer Scientists},
 booktitle = {Proceedings of the 12th European Conference on Genetic Programming},
 series = {EuroGP '09},
 year = {2009},
 isbn = {978-3-642-01180-1},
 location = {T\&\#252;bingen, Germany},
 pages = {195--207},
 numpages = {13},
 url = {http://dx.doi.org/10.1007/978-3-642-01181-8_17},
 doi = {10.1007/978-3-642-01181-8_17},
 acmid = {1533515},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@article{Music,
title = "A new meta-heuristic algorithm for continuous engineering optimization: harmony search theory and practice ",
journal = "Computer Methods in Applied Mechanics and Engineering ",
volume = "194",
number = "36–38",
pages = "3902 - 3933",
year = "2005",
note = "",
issn = "0045-7825",
doi = "http://dx.doi.org/10.1016/j.cma.2004.09.007",
url = "http://www.sciencedirect.com/science/article/pii/S0045782504004682",
author = "Kang Seok Lee and Zong Woo Geem",
keywords = "Harmony search",
keywords = "Heuristic algorithm",
keywords = "Continuous design variables",
keywords = "Mathematical function minimization",
keywords = "Structural engineering optimization "
}

@Inbook{GE,
author="O'Neil, Michael
and Ryan, Conor",
title="Grammatical Evolution",
bookTitle="Grammatical Evolution: Evolutionary Automatic Programming in an Arbitrary Language",
year="2003",
publisher="Springer US",
address="Boston, MA",
pages="33--47",
isbn="978-1-4615-0447-4",
doi="10.1007/978-1-4615-0447-4_4",
url="http://dx.doi.org/10.1007/978-1-4615-0447-4_4",
}

@InProceedings{GEDE,
  author =       "Michael O'Neill and Anthony Brabazon",
  title =        "Grammatical Differential Evolution",
  booktitle =    "Proceedings of the 2006 International Conference on
                 Artificial Intelligence, ICAI 2006",
  year =         "2006",
  editor =       "Hamid R. Arabnia",
  volume =       "1",
  pages =        "231--236",
  address =      "Las Vegas, Nevada, USA",
  month =        jun # " 26-29",
  publisher =    "CSREA Press",
  keywords =     "genetic algorithms, genetic programming, Grammatical
                 evolution, differential evolution, automatic program
                 generation",
  ISBN =         "1-932415-96-3",
  bibsource =    "DBLP, http://dblp.uni-trier.de",
  URL =          "http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.91.3012",
  URL =          "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.91.3012.pdf",
  size =         "6 pages",
  abstract =     "This proof of concept study examines the possibility
                 of specifying the construction of programs using
                 Differential Evolution, and represents a new form of
                 grammar-based genetic programming, Grammatical
                 Differential Evolution (GDE). In GDE each individual
                 member of the population represents a specific choice
                 of program construction rules, where these rules are
                 specified using a Backus-Naur Form grammar. The results
                 demonstrate that it is possible to generate programs
                 using the Grammatical Differential technique.",
  notes =        "BNF, DE/rand/1/bin. Real valued vector converted to
                 nearest integers for GE codon. Santa Fe ant
                 \cite{langdon:1998:antspace}, x+x^2+x^3+x^4, 3-mux,
                 Mastermind. Gramatical Swarm",
}

@MISC{PSO,
    author = {James Kennedy and Russell Eberhart},
    title = {Particle swarm optimization},
    year = {1995}
}

@article{PSOBias,
 author = {Spears, William M. and Green, Derek T. and Spears, Diana F.},
 title = {Biases in Particle Swarm Optimization},
 journal = {Int. J. Swarm. Intell. Res.},
 issue_date = {April 2010},
 volume = {1},
 number = {2},
 month = apr,
 year = {2010},
 issn = {1947-9263},
 pages = {34--57},
 numpages = {24},
 url = {http://dx.doi.org/10.4018/jsir.2010040103},
 doi = {10.4018/jsir.2010040103},
 acmid = {2440943},
 publisher = {IGI Global},
 address = {Hershey, PA, USA},
 keywords = {Algorithms, Bias, Particle Swarm Optimization, Probabilistic Systems, Theoretical Analysis},
} 

@Article{PSOBiasAlg,
author="Bonyadi, Mohammad Reza
and Michalewicz, Zbigniew",
title="A locally convergent rotationally invariant particle swarm optimization algorithm",
journal="Swarm Intelligence",
year="2014",
volume="8",
number="3",
pages="159--198",
abstract="Several well-studied issues in the particle swarm optimization algorithm are outlined and some earlier methods that address these issues are investigated from the theoretical and experimental points of view. These issues are the: stagnation of particles in some points in the search space, inability to change the value of one or more decision variables, poor performance when the swarm size is small, lack of guarantee to converge even to a local optimum (local optimizer), poor performance when the number of dimensions grows, and sensitivity of the algorithm to the rotation of the search space. The significance of each of these issues is discussed and it is argued that none of the particle swarm optimizers we are aware of can address all of these issues at the same time. To address all of these issues at the same time, a new general form of velocity update rule for the particle swarm optimization algorithm that contains a user-definable function                                                                           {\$}{\$}f{\$}{\$}                                                            f                                                       is proposed. It is proven that the proposed velocity update rule guarantees to address all of these issues if the function                                                                           {\$}{\$}f{\$}{\$}                                                            f                                                       satisfies the following two conditions: (i) the function                                                                           {\$}{\$}f{\$}{\$}                                                            f                                                       is designed in such a way that for any input vector                                                                           {\$}{\$}{\backslash}vec {\{}y{\}}{\$}{\$}                                                                                    y                        {\textrightarrow}                                                                             in the search space, there exists a region                                                                           {\$}{\$}A{\$}{\$}                                                            A                                                       which contains                                                                           {\$}{\$}{\backslash}vec {\{}y{\}}{\$}{\$}                                                                                    y                        {\textrightarrow}                                                                             and                                                                           {\$}{\$} f{\backslash}!{\backslash}left( {\{}{\backslash}vec {\{}y{\}}{\}} {\backslash}right) {\$}{\$}                                                                                    f                                                                                                      y                            {\textrightarrow}                                                                                                                               can be located anywhere in                                                                           {\$}{\$}A{\$}{\$}                                                            A                                                      , and (ii)                                                                           {\$}{\$}f{\$}{\$}                                                            f                                                       is invariant under any affine transformation. An example of function                                                                           {\$}{\$}f{\$}{\$}                                                            f                                                       is provided that satisfies these conditions and its performance is examined through some experiments. The experiments confirm that the proposed algorithm (with an appropriate function                                                                           {\$}{\$}f){\$}{\$}                                                                                    f                        )                                                                             can effectively address all of these issues at the same time. Also, comparisons with earlier methods show that the overall ability of the proposed method for solving benchmark functions is significantly better.",
issn="1935-3820",
doi="10.1007/s11721-014-0095-1",
url="http://dx.doi.org/10.1007/s11721-014-0095-1"
}
@Inbook{SRBaseline,
author="Korns, Michael F.",
editor="Riolo, Rick
and Vladislavleva, Ekaterina
and Ritchie, Marylyn D
and Moore, Jason H.",
title="A Baseline Symbolic Regression Algorithm",
bookTitle="Genetic Programming Theory and Practice X",
year="2013",
publisher="Springer New York",
address="New York, NY",
pages="117--137",
isbn="978-1-4614-6846-2",
doi="10.1007/978-1-4614-6846-2_9",
url="http://dx.doi.org/10.1007/978-1-4614-6846-2_9"
}



@Inbook{SRAccuracy,
author="Korns, Michael F.",
editor="Riolo, Rick
and Vladislavleva, Ekaterina
and Moore, Jason H.",
title="Accuracy in Symbolic Regression",
bookTitle="Genetic Programming Theory and Practice IX",
year="2011",
publisher="Springer New York",
address="New York, NY",
pages="129--151",
isbn="978-1-4614-1770-5",
doi="10.1007/978-1-4614-1770-5_8",
url="http://dx.doi.org/10.1007/978-1-4614-1770-5_8"
}



@inproceedings{PSONoiseInverse,
 author = {Vakili, S. and Gadala, M. S.},
 title = {Effectiveness of Particle Swarm Optimization Technique in Dealing with Noisy Data in Inverse Heat Conduction Analysis},
 booktitle = {Proceedings of the 2009 Summer Computer Simulation Conference},
 series = {SCSC '09},
 year = {2009},
 location = {Istanbul, Turkey},
 pages = {40--48},
 numpages = {9},
 url = {http://dl.acm.org/citation.cfm?id=2349508.2349513},
 acmid = {2349513},
 publisher = {Society for Modeling \&\#38; Simulation International},
 address = {Vista, CA},
 keywords = {heat transfer, inverse analysis, noisy data, particle swarm optimization, stochastical method},
} 

@article{PSOExplosion,
 author = {Clerc, M. and Kennedy, J.},
 title = {The Particle Swarm - Explosion, Stability, and Convergence in a Multidimensional Complex Space},
 journal = {Trans. Evol. Comp},
 issue_date = {February 2002},
 volume = {6},
 number = {1},
 month = feb,
 year = {2002},
 issn = {1089-778X},
 pages = {58--73},
 numpages = {16},
 url = {http://dx.doi.org/10.1109/4235.985692},
 doi = {10.1109/4235.985692},
 acmid = {2221574},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
} 

@inproceedings{PSODiversity,
 author = {Monson, Christopher K. and Seppi, Kevin D.},
 title = {Adaptive Diversity in PSO},
 booktitle = {Proceedings of the 8th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '06},
 year = {2006},
 isbn = {1-59593-186-4},
 location = {Seattle, Washington, USA},
 pages = {59--66},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1143997.1144006},
 doi = {10.1145/1143997.1144006},
 acmid = {1144006},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {adaptation, optimization, swarm intelligence},
} 

@inproceedings{PSOTopology,
 author = {Montes de Oca, Marco A. and St\"{u}tzle, Thomas},
 title = {Convergence Behavior of the Fully Informed Particle Swarm Optimization Algorithm},
 booktitle = {Proceedings of the 10th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '08},
 year = {2008},
 isbn = {978-1-60558-130-9},
 location = {Atlanta, GA, USA},
 pages = {71--78},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1389095.1389106},
 doi = {10.1145/1389095.1389106},
 acmid = {1389106},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {experiments, particle swarm optimization, swarm intelligence},
} 
@article{LPSO,
title = "A novel particle swarm optimization algorithm with Levy flight ",
journal = "Applied Soft Computing ",
volume = "23",
number = "",
pages = "333 - 345",
year = "2014",
note = "",
issn = "1568-4946",
doi = "http://dx.doi.org/10.1016/j.asoc.2014.06.034",
url = "http://www.sciencedirect.com/science/article/pii/S1568494614003081",
author = "Hüseyin Haklı and Harun Uğuz",
keywords = "Particle swarm optimization",
keywords = "Levy flight",
keywords = "Levy distribution",
keywords = "Optimization ",
abstract = "Abstract Particle swarm optimization (PSO) is one of the well-known population-based techniques used in global optimization and many engineering problems. Despite its simplicity and efficiency, the \{PSO\} has problems as being trapped in local minima due to premature convergence and weakness of global search capability. To overcome these disadvantages, the \{PSO\} is combined with Levy flight in this study. Levy flight is a random walk determining stepsize using Levy distribution. Being used Levy flight, a more efficient search takes place in the search space thanks to the long jumps to be made by the particles. In the proposed method, a limit value is defined for each particle, and if the particles could not improve self-solutions at the end of current iteration, this limit is increased. If the limit value determined is exceeded by a particle, the particle is redistributed in the search space with Levy flight method. To get rid of local minima and improve global search capability are ensured via this distribution in the basic PSO. The performance and accuracy of the proposed method called as Levy flight particle swarm optimization (LFPSO) are examined on well-known unimodal and multimodal benchmark functions. Experimental results show that the \{LFPSO\} is clearly seen to be more successful than one of the state-of-the-art \{PSO\} (SPSO) and the other \{PSO\} variants in terms of solution quality and robustness. The results are also statistically compared, and a significant difference is observed between the \{SPSO\} and the \{LFPSO\} methods. Furthermore, the results of proposed method are also compared with the results of well-known and recent population-based optimization methods. "
}


@inproceedings{ACOTheory,
	address = {New York, NY, USA},
	series = {{GECCO} '07},
	title = {On the {Runtime} {Analysis} of the 1-{ANT} {ACO} {Algorithm}},
	isbn = {978-1-59593-697-4},
	url = {http://doi.acm.org/10.1145/1276958.1276964},
	doi = {10.1145/1276958.1276964},
	abstract = {The runtime analysis of randomized search heuristics is a growing field where, in the last two decades, many rigorous results have been obtained. These results, however, apply particularly to classical search heuristics such as Evolutionary Algorithms (EAs) and Simulated Annealing. First runtime analyses of modern search heuristics have been conducted only recently w.r.t a simple Ant Colony Optimization (ACO) algorithm called 1-ANT. In particular, the influence of the evaporation factor in the pheromone update mechanism and the robustness of this parameter w.r.t the runtime behavior have been determined for the example function OneMax.This paper puts forward the rigorous runtime analysis of the 1-ANT on example functions, namely on the functions LeadingOnes and BinVal. With respect to EAs, such analyses have been essential to develop methods for the analysis on more complicated problems. The proof techniques required for the 1-ANT, unfortunately, differ significantly from those for EAs, which means that a new reservoir of methods has to be built up. Again, the influence of the evaporation factor is analyzed rigorously, and it is proved that its choice can be very crucial to allow efficient runtimes. Moreover, the analyses provide insight into the working principles of ACO algorithms and, in terms of their robustness, describe essential differences to other randomized search heuristics.},
	urldate = {2016-08-15},
	booktitle = {Proceedings of the 9th {Annual} {Conference} on {Genetic} and {Evolutionary} {Computation}},
	publisher = {ACM},
	author = {Doerr, Benjamin and Neumann, Frank and Sudholt, Dirk and Witt, Carsten},
	year = {2007},
	keywords = {Ant Colony Optimization, runtime analysis},
	pages = {33--40},
	file = {ACM Full Text PDF:/home/bcardoen/.mozilla/firefox/un9nfpe4.default/zotero/storage/6AS2EII6/Doerr et al. - 2007 - On the Runtime Analysis of the 1-ANT ACO Algorithm.pdf:application/pdf}
}


@inproceedings{ACONoise,
	address = {New York, NY, USA},
	series = {{GECCO} '15},
	title = {Robustness of {Ant} {Colony} {Optimization} to {Noise}},
	isbn = {978-1-4503-3472-3},
	url = {http://doi.acm.org/10.1145/2739480.2754723},
	doi = {10.1145/2739480.2754723},
	abstract = {Recently Ant Colony Optimization (ACO) algorithms have been proven to be efficient in uncertain environments, such as noisy or dynamically changing fitness functions. Most of these analyses focus on combinatorial problems, such as path finding. We analyze an ACO algorithm in a setting where we try to optimize the simple OneMax test function, but with additive posterior noise sampled from a Gaussian distribution. Without noise the classical (μ+1)-EA outperforms any ACO algorithm, with smaller μ being better; however, with large noise, the (μ+1)-EA fails, even for high values of μ (which are known to help against small noise). In this paper we show that ACO is able to deal with arbitrarily large noise in a graceful manner, that is, as long as the evaporation factor p is small enough dependent on the parameter δ2 of the noise and the dimension \$n\$ of the search space (p= o(1/(n(n + δlog n)2 log n))), optimization will be successful.},
	urldate = {2016-08-15},
	booktitle = {Proceedings of the 2015 {Annual} {Conference} on {Genetic} and {Evolutionary} {Computation}},
	publisher = {ACM},
	author = {Friedrich, Tobias and Kötzing, Timo and Krejca, Martin S. and Sutton, Andrew M.},
	year = {2015},
	keywords = {Ant Colony Optimization, noisy fitness, run time analysis, theory},
	pages = {17--24},
	file = {ACM Full Text PDF:/home/bcardoen/.mozilla/firefox/un9nfpe4.default/zotero/storage/KAGJPKIN/Friedrich et al. - 2015 - Robustness of Ant Colony Optimization to Noise.pdf:application/pdf}
}

@inproceedings{ACODelay,
	address = {New York, NY, USA},
	series = {{GECCO} '12},
	title = {{CGrAnt}: {A} {Swarm} {Intelligence}-based {Routing} {Protocol} for {Delay} {Tolerant} {Networks}},
	isbn = {978-1-4503-1177-9},
	shorttitle = {{CGrAnt}},
	url = {http://doi.acm.org/10.1145/2330163.2330169},
	doi = {10.1145/2330163.2330169},
	abstract = {This paper presents a new routing protocol for Delay Tolerant Networks (DTNs), based on a distributed swarm intelligence approach. The protocol is called Cultural Greedy Ant (CGrAnt), as it uses a Cultural Algorithm (CA) and a greedy version of the Ant Colony Optimization (ACO) metaheuristic. The term greedy implies the use of a deterministic transition rule to exploit previously found good paths or explore new paths by selecting, from among a set of candidates, the most promising message forwarders. CGrAnt chooses each next node toward the message destination based on pheromone concentration (i.e., global information) whenever it is available. However, as the pheromone is not always available due to connectivity partitions, local information (i.e., heuristic function) captured from DTN nodes also supports a routing decision. Specific metrics and information gathered from the evolution are stored in Situational, Domain, and Historical Knowledge. The knowledge composes the CA's belief space, which is used to guide and improve the search. CGrAnt is compared with two DTN routing protocols (Epidemic and PROPHET) in an activity-based scenario. The results show that CGrAnt achieves a higher delivery ratio and lower byte redundancy than Epidemic and PROPHET.},
	urldate = {2016-08-15},
	booktitle = {Proceedings of the 14th {Annual} {Conference} on {Genetic} and {Evolutionary} {Computation}},
	publisher = {ACM},
	author = {Vendramin, Ana Cristina Barreiras Kochem and Munaretto, Anelise and Delgado, Myriam Regattieri de Biase da Silva and Viana, Aline Carneiro},
	year = {2012},
	keywords = {Ant Colony Optimization, cultural algorithms, delay tolerant network, routing protocol, social metrics},
	pages = {33--40},
	file = {ACM Full Text PDF:/home/bcardoen/.mozilla/firefox/un9nfpe4.default/zotero/storage/AVA2RZFD/Vendramin et al. - 2012 - CGrAnt A Swarm Intelligence-based Routing Protoco.pdf:application/pdf}
}

@inproceedings{ACODOE,
 author = {Ridge, Enda and Kudenko, Daniel},
 title = {Screening the Parameters Affecting Heuristic Performance},
 booktitle = {Proceedings of the 9th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '07},
 year = {2007},
 isbn = {978-1-59593-697-4},
 location = {London, England},
 pages = {180--180},
 numpages = {1},
 url = {http://doi.acm.org/10.1145/1276958.1276994},
 doi = {10.1145/1276958.1276994},
 acmid = {1276994},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ant colony, design of experiments, parameter screening},
}

@book{ACOParallel,
 author = {Dorigo, Marco and St\"{u}tzle, Thomas},
 title = {Ant Colony Optimization},
 year = {2004},
 isbn = {0262042193},
 publisher = {Bradford Company},
 address = {Scituate, MA, USA},
 pages = {84--86},
} 

@ARTICLE{ACOMultimodal, 
author={Q. Yang and W. N. Chen and Z. Yu and T. Gu and Y. Li and H. Zhang and J. Zhang}, 
journal={IEEE Transactions on Evolutionary Computation}, 
title={Adaptive Multimodal Continuous Ant Colony Optimization}, 
year={2016}, 
volume={PP}, 
number={99}, 
pages={1-1}, 
keywords={Algorithm design and analysis;Ant colony optimization;Clustering algorithms;Computer science;Optimization;Sociology;Statistics;Ant colony optimization;multimodal optimization;multiple global optima;niching}, 
doi={10.1109/TEVC.2016.2591064}, 
ISSN={1089-778X}, 
month={},}


@Inbook{ABC,
author="Karaboga, Dervis
and Akay, Bahriye
and Ozturk, Celal",
editor="Torra, Vicen{\c{c}}
and Narukawa, Yasuo
and Yoshida, Yuji",
title="Artificial Bee Colony (ABC) Optimization Algorithm for Training Feed-Forward Neural Networks",
bookTitle="Modeling Decisions for Artificial Intelligence: 4th International Conference, MDAI 2007, Kitakyushu, Japan, August 16-18, 2007. Proceedings",
year="2007",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="318--329",
isbn="978-3-540-73729-2",
doi="10.1007/978-3-540-73729-2_30",
url="http://dx.doi.org/10.1007/978-3-540-73729-2_30"
}

@inproceedings{ABCLevy,
	title = {Levy mutated {Artificial} {Bee} {Colony} algorithm for global optimization},
	doi = {10.1109/ICSMC.2011.6083786},
	abstract = {This paper proposes an improved version of Artificial Bee Colony (ABC) algorithm with mutation based on Levy Probability Distributions. The Levy distribution has a peculiar property of generating an offspring farther away from its parent which depends on internal parameter α compared to that of Gaussian mutations, this property enables in finding out most optimal solutions to the problems than that of conventional methods. The proposed algorithm is tested on 7 standard benchmark functions and on a set of non-traditional problems suggested in the special session of CEC'2008. Analysis and comparison of results with other state of art optimization algorithms like GA and PSO, shows the superiority of improved mutation, especially on high dimensional problems. This paper finally investigates the performance of proposed algorithm on the frequency-modulated sound wave synthesis problem, a real world problem in the field on communication engineering.},
	booktitle = {2011 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Rajasekhar, A. and Abraham, A. and Pant, M.},
	month = oct,
	year = {2011},
	keywords = {Algorithm design and analysis, artificial bees, Bee frequency modulated sound, Benchmark testing, communication engineering, Electronic mail, Gaussian distribution, Gaussian mutations, genetic algorithms, global optimization, levy mutated artificial bee colony algorithm, levy probability distributions, Mathematical model, optimisation, Optimization, Probability distribution},
	pages = {655--662},
	file = {IEEE Xplore Abstract Record:/home/bcardoen/.mozilla/firefox/un9nfpe4.default/zotero/storage/94BJFU4D/6083786.html:text/html}
}

@book{DOEParameter,
  title={Design of experiments for the tuning of optimisation algorithms},
  author={Ridge, Enda},
  year={2007},
  publisher={University of York, Department of Computer Science}
}

@article{ABCMulti,
title = "A multi-objective artificial bee colony algorithm ",
journal = "Swarm and Evolutionary Computation ",
volume = "2",
number = "",
pages = "39 - 52",
year = "2012",
note = "",
issn = "2210-6502",
doi = "http://dx.doi.org/10.1016/j.swevo.2011.08.001",
url = "http://www.sciencedirect.com/science/article/pii/S2210650211000411",
author = "Reza Akbari and Ramin Hedayatzadeh and Koorush Ziarati and Bahareh Hassanizadeh",
keywords = "Artificial bee colony",
keywords = "Multi-objective optimization",
keywords = "Multi-objective artificial bee colony ",
abstract = "This work presents a multi-objective optimization method based on the artificial bee colony, called the MOABC, for optimizing problems with multiple objectives. The \{MOABC\} uses a grid-based approach to adaptively assess the Pareto front maintained in an external archive. The external archive is used to control the flying behaviours of the individuals and structuring the bee colony. The employed bees adjust their trajectories based on the non-dominated solutions maintained in the external archive. On the other hand, the onlooker bees select the food sources advertised by the employed bees to update their positions. The qualities of these food sources are computed based on the Pareto dominance notion. The scout bees are used by the \{MOABC\} to get rid of food sources with poor qualities. The proposed algorithm was evaluated on a set of standard test problems in comparison with other state-of-the-art algorithms. Experimental results indicate that the proposed approach is competitive compared to other algorithms considered in this work. "
}

@article{ABCSR,
 author = {Karaboga, Dervis and Ozturk, Celal and Karaboga, Nurhan and Gorkemli, Beyza},
 title = {Artificial Bee Colony Programming for Symbolic Regression},
 journal = {Inf. Sci.},
 issue_date = {November, 2012},
 volume = {209},
 month = nov,
 year = {2012},
 issn = {0020-0255},
 pages = {1--15},
 numpages = {15},
 url = {http://dx.doi.org/10.1016/j.ins.2012.05.002},
 doi = {10.1016/j.ins.2012.05.002},
 acmid = {2318367},
 publisher = {Elsevier Science Inc.},
 address = {New York, NY, USA},
 keywords = {Artificial bee colony algorithm, Artificial bee colony programming, Genetic programming, Symbolic regression},
}

@article{ABCPSO,
title = "PS–ABC: A hybrid algorithm based on particle swarm and artificial bee colony for high-dimensional optimization problems ",
journal = "Expert Systems with Applications ",
volume = "42",
number = "22",
pages = "8881 - 8895",
year = "2015",
note = "",
issn = "0957-4174",
doi = "http://dx.doi.org/10.1016/j.eswa.2015.07.043",
url = "http://www.sciencedirect.com/science/article/pii/S0957417415005035",
author = "Zhiyong Li and Weiyou Wang and Yanyan Yan and Zheng Li",
keywords = "Particle swarm optimization",
keywords = "Artificial bee colony",
keywords = "Hybrid algorithm",
keywords = "High-dimensional optimization problems ",
abstract = "Abstract Particle swarm optimization (PSO) and artificial bee colony (ABC) are new optimization methods that have attracted increasing research interests because of its simplicity and efficiency. However, when being applied to high-dimensional optimization problems, \{PSO\} algorithm may be trapped in the local optimal because of its low global exploration efficiency; \{ABC\} algorithm has slower convergence speed in some cases because of the lack of powerful local exploitation capacity. In this paper, we propose a hybrid algorithm called PS–ABC, which combines the local search phase in \{PSO\} with two global search phases in \{ABC\} for the global optimum. In the iteration process, the algorithm examines the aging degree of pbest for each individual to decide which type of search phase (PSO phase, onlooker bee phase, and modified scout bee phase) to adopt. The proposed PS–ABC algorithm is validated on 13 high-dimensional benchmark functions from the IEEE-CEC 2014 competition problems, and it is compared with ABC, PSO, HPA, ABC–PS and \{OXDE\} algorithms. Results show that the PS–ABC algorithm is an efficient, fast converging and robust optimization method for solving high-dimensional optimization problems. "
}

@article{ABCChaos,
title = "Chaotic artificial bee colony approach to Uninhabited Combat Air Vehicle (UCAV) path planning ",
journal = "Aerospace Science and Technology ",
volume = "14",
number = "8",
pages = "535 - 541",
year = "2010",
note = "",
issn = "1270-9638",
doi = "http://dx.doi.org/10.1016/j.ast.2010.04.008",
url = "http://www.sciencedirect.com/science/article/pii/S1270963810000507",
author = "Chunfang Xu and Haibin Duan and Fang Liu",
keywords = "Uninhabited Combat Air Vehicle (UCAV)",
keywords = "Artificial Bee Colony (ABC)",
keywords = "Chaos theory",
keywords = "Path planning ",
abstract = "Path planning of Uninhabited Combat Air Vehicle (UCAV) is a rather complicated global optimum problem which is about seeking a superior flight route considering the different kinds of constrains under complex combat field environment. Artificial Bee Colony (ABC) algorithm is a new optimization method motivated by the intelligent behavior of honey bees. In this paper, we propose an improved \{ABC\} optimization algorithm based on chaos theory for solving the \{UCAV\} path planning in various combat field environments, and the implementation procedure of our proposed chaotic \{ABC\} approach is also described in detail. Series of experimental comparison results are presented to show the feasibility, effectiveness and robustness of our proposed method. "
}

@Article{DE,
author="Storn, Rainer
and Price, Kenneth",
title="Differential Evolution -- A Simple and Efficient Heuristic for global Optimization over Continuous Spaces",
journal="Journal of Global Optimization",
year="1997",
volume="11",
number="4",
pages="341--359",
abstract="A new heuristic approach for minimizing possiblynonlinear and non-differentiable continuous spacefunctions is presented. By means of an extensivetestbed it is demonstrated that the new methodconverges faster and with more certainty than manyother acclaimed global optimization methods. The newmethod requires few control variables, is robust, easyto use, and lends itself very well to parallelcomputation.",
issn="1573-2916",
doi="10.1023/A:1008202821328",
url="http://dx.doi.org/10.1023/A:1008202821328"
}

@article{DEParallel,
	title = {Differential {Evolution}: {A} {Survey} of the {State}-of-the-{Art}},
	volume = {15},
	issn = {1089-778X},
	shorttitle = {Differential {Evolution}},
	doi = {10.1109/TEVC.2010.2059031},
	abstract = {Differential evolution (DE) is arguably one of the most powerful stochastic real-parameter optimization algorithms in current use. DE operates through similar computational steps as employed by a standard evolutionary algorithm (EA). However, unlike traditional EAs, the DE-variants perturb the current-generation population members with the scaled differences of randomly selected and distinct population members. Therefore, no separate probability distribution has to be used for generating the offspring. Since its inception in 1995, DE has drawn the attention of many researchers all over the world resulting in a lot of variants of the basic algorithm with improved performance. This paper presents a detailed review of the basic concepts of DE and a survey of its major variants, its application to multiobjective, constrained, large scale, and uncertain optimization problems, and the theoretical studies conducted on DE so far. Also, it provides an overview of the significant engineering applications that have benefited from the powerful nature of DE.},
	number = {1},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Das, S. and Suganthan, P. N.},
	month = feb,
	year = {2011},
	keywords = {constrained optimization, Derivative-free optimization, differential evolution, differential evolution (DE), direct search, evolutionary algorithm, evolutionary algorithms (EAs), evolutionary computation, genetic algorithms (GAs), large scale uncertain optimization, Metaheuristics, multiobjective optimization, optimisation, Particle swarm optimization (PSO), random processes, random selection, Stochastic processes, stochastic real-parameter optimization algorithm},
	pages = {18--19},
	file = {IEEE Xplore Abstract Record:/home/bcardoen/.mozilla/firefox/un9nfpe4.default/zotero/storage/G37NZCES/5601760.html:text/html}
}

@article{DiscreteDE,
title = "A discrete differential evolution algorithm for the permutation flowshop scheduling problem ",
journal = "Computers and Industrial Engineering ",
volume = "55",
number = "4",
pages = "795 - 816",
year = "2008",
note = "",
issn = "0360-8352",
doi = "http://dx.doi.org/10.1016/j.cie.2008.03.003",
url = "http://www.sciencedirect.com/science/article/pii/S0360835208000582",
author = "Quan-Ke Pan and Mehmet Fatih Tasgetiren and Yun-Chia Liang",
keywords = "Permutation flowshop Scheduling",
keywords = "Iterated greedy algorithm",
keywords = "Discrete differential evolution algorithm",
keywords = "Discrete particle swarm optimization",
keywords = "Referenced local search ",
abstract = "Very recently, Pan et al. [Proceedings of the 9th Annual Conference on Genetic and Evolutionary Computation, GECCO07, pp. 126–33] presented a new and novel discrete differential evolution algorithm for the permutation flowshop scheduling problem with the makespan criterion. On the other hand, the iterated greedy algorithm is proposed by [Ruiz, R., &amp; Stützle, T. (2007). A simple and effective iterated greedy algorithm for the permutation flowshop scheduling problem. European Journal of Operational Research, 177(3), 2033–49] for the permutation flowshop scheduling problem with the makespan criterion. However, both algorithms are not applied to the permutation flowshop scheduling problem with the total flowtime criterion. Based on their excellent performance with the makespan criterion, we extend both algorithms in this paper to the total flowtime objective. Furthermore, we propose a new and novel referenced local search procedure hybridized with both algorithms to further improve the solution quality. The referenced local search exploits the space based on reference positions taken from a reference solution in the hope of finding better positions for jobs when performing insertion operation. Computational results show that both algorithms with the referenced local search are either better or highly competitive to all the existing approaches in the literature for both objectives of makespan and total flowtime. Especially for the total flowtime criterion, their performance is superior to the particle swarm optimization algorithms proposed by [Tasgetiren, M. F., Liang, Y. -C., Sevkli, M., Gencyilmaz, G. (2007). Particle swarm optimization algorithm for makespan and total flowtime minimization in permutation flowshop sequencing problem. European Journal of Operational Research, 177(3), 1930–47] and [Jarboui, B., Ibrahim, S., Siarry, P., Rebai, A. (2007). A combinatorial particle swarm optimisation for solving permutation flowshop problems. Computers &amp; Industrial Engineering, doi:10.1016/j.cie.2007.09.006]. Ultimately, for Taillard’s benchmark suite, four best known solutions for the makespan criterion as well as 40 out of the 90 best known solutions for the total flowtime criterion are further improved by either one of the algorithms presented in this paper. "
}

@Inbook{DEPSO,
author="Sarkar, Soham
and Das, Swagatam",
editor="Panigrahi, Bijaya Ketan
and Das, Swagatam
and Suganthan, Ponnuthurai Nagaratnam
and Dash, Subhransu Sekhar",
title="A Hybrid Particle Swarm with Differential Evolution Operator Approach (DEPSO) for Linear Array Synthesis",
bookTitle="Swarm, Evolutionary, and Memetic Computing: First International Conference on Swarm, Evolutionary, and Memetic Computing, SEMCCO 2010, Chennai, India, December 16-18, 2010. Proceedings",
year="2010",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="416--423",
isbn="978-3-642-17563-3",
doi="10.1007/978-3-642-17563-3_50",
url="http://dx.doi.org/10.1007/978-3-642-17563-3_50"
}



@article{DEAdapt,
 author = {Brest, J. and Greiner, S. and Boskovic, B. and Mernik, M. and Zumer, V.},
 title = {Self-Adapting Control Parameters in Differential Evolution: A Comparative Study on Numerical Benchmark Problems},
 journal = {Trans. Evol. Comp},
 issue_date = {December 2006},
 volume = {10},
 number = {6},
 month = dec,
 year = {2006},
 issn = {1089-778X},
 pages = {646--657},
 numpages = {12},
 url = {http://dx.doi.org/10.1109/TEVC.2006.872133},
 doi = {10.1109/TEVC.2006.872133},
 acmid = {2221799},
 publisher = {IEEE Press},
 address = {Piscataway, NJ, USA},
 keywords = {Adaptive parameter control, differential evolution (DE), evolutionary optimization},
} 

@article{DESurveyLatest,
title = "Recent advances in differential evolution – An updated survey ",
journal = "Swarm and Evolutionary Computation ",
volume = "27",
number = "",
pages = "1 - 30",
year = "2016",
note = "",
issn = "2210-6502",
doi = "http://dx.doi.org/10.1016/j.swevo.2016.01.004",
url = "http://www.sciencedirect.com/science/article/pii/S2210650216000146",
author = "Swagatam Das and Sankha Subhra Mullick and P.N. Suganthan",
keywords = "Differential evolution",
keywords = "Continuous evolutionary optimization",
keywords = "Numerical optimization",
keywords = "Parameter adaptation",
keywords = "Recombination ",
abstract = "Abstract Differential Evolution (DE) is arguably one of the most powerful and versatile evolutionary optimizers for the continuous parameter spaces in recent times. Almost 5 years have passed since the first comprehensive survey article was published on \{DE\} by Das and Suganthan in 2011. Several developments have been reported on various aspects of the algorithm in these 5 years and the research on and with \{DE\} have now reached an impressive state. Considering the huge progress of research with \{DE\} and its applications in diverse domains of science and technology, we find that it is a high time to provide a critical review of the latest literatures published and also to point out some important future avenues of research. The purpose of this paper is to summarize and organize the information on these current developments on DE. Beginning with a comprehensive foundation of the basic \{DE\} family of algorithms, we proceed through the recent proposals on parameter adaptation of DE, DE-based single-objective global optimizers, \{DE\} adopted for various optimization scenarios including constrained, large-scale, multi-objective, multi-modal and dynamic optimization, hybridization of \{DE\} with other optimizers, and also the multi-faceted literature on applications of DE. The paper also presents a dozen of interesting open problems and future research issues on DE. "
}

@Inbook{SRGE,
author="Korns, Michael F.",
editor="Riolo, Rick
and McConaghy, Trent
and Vladislavleva, Ekaterina",
title="Abstract Expression Grammar Symbolic Regression",
bookTitle="Genetic Programming Theory and Practice VIII",
year="2011",
publisher="Springer New York",
address="New York, NY",
pages="109--128",
isbn="978-1-4419-7747-2",
doi="10.1007/978-1-4419-7747-2_7",
url="http://dx.doi.org/10.1007/978-1-4419-7747-2_7"
}

@article{GPSemantics,
  title={Semantically-based crossover in genetic programming: application to real-valued symbolic regression},
  author={Uy, Nguyen Quang and Hoai, Nguyen Xuan and O’Neill, Michael and McKay, Robert I and Galv{\'a}n-L{\'o}pez, Edgar},
  journal={Genetic Programming and Evolvable Machines},
  volume={12},
  number={2},
  pages={91--119},
  year={2011},
  publisher={Springer US}
}

@INPROCEEDINGS{GPConst,
    author = {Matthew Evett and Thomas Fernandez},
    title = {Numeric Mutation Improves the Discovery of Numeric Constants in Genetic Programming},
    booktitle = {in Genetic Programming.” In},
    year = {1998},
    pages = {66--71},
    publisher = {Morgan Kaufmann}
}

@MISC{GPDE,
    author = {Brian M. Cerny and Peter C. Nelson and Chi Zhou},
    title = {Using Differential Evolution for Symbolic Regression and Numerical Constant Creation},
    year = {}
}

@inproceedings{GrammarConstant,
 author = {Dempsey, Ian and O'Neill, Michael and Brabazon, Anthony},
 title = {Meta-grammar Constant Creation with Grammatical Evolution by Grammatical Evolution},
 booktitle = {Proceedings of the 7th Annual Conference on Genetic and Evolutionary Computation},
 series = {GECCO '05},
 year = {2005},
 isbn = {1-59593-010-8},
 location = {Washington DC, USA},
 pages = {1665--1671},
 numpages = {7},
 url = {http://doi.acm.org/10.1145/1068009.1068289},
 doi = {10.1145/1068009.1068289},
 acmid = {1068289},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {constant creation, digit concatenation, ephemeral random constants, genetic programming, grammatical evolution, meta-grammars},
} 

@book{FieldGuideGP,
 author = {Poli, Riccardo and Langdon, William B. and McPhee, Nicholas Freitag},
 title = {A Field Guide to Genetic Programming},
 year = {2008},
 isbn = {1409200736, 9781409200734},
 publisher = {Lulu Enterprises, UK Ltd},
} 

@book{IntroGP,
 author = {Banzhaf, Wolfgang and Francone, Frank D. and Keller, Robert E. and Nordin, Peter},
 title = {Genetic Programming: An Introduction: on the Automatic Evolution of Computer Programs and Its Applications},
 year = {1998},
 isbn = {1-55860-510-X},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
} 

@InCollection{BaselineGP,
    author =       "Michael F. Korns",
    title =        "A Baseline Symbolic Regression Algorithm",
    booktitle =    "Genetic Programming Theory and Practice X",
    year =         "2012",
    series =       "Genetic and Evolutionary Computation",
    editor =       "Rick Riolo and Ekaterina Vladislavleva and 
    Marylyn D. Ritchie and Jason H. Moore",
    publisher =    "Springer",
    chapter =      "9",
    pages =        "117--137",
    address =      "Ann Arbor, USA",
    month =        "12-14 " # may,
    keywords =     "genetic algorithms, genetic programming, Abstract
    expression grammars, Grammar template genetic
    programming, Particle swarm, Symbolic regression",
    isbn13 =       "978-1-4614-6845-5",
    URL =          "http://dx.doi.org/10.1007/978-1-4614-6846-2_9",
    doi =          "doi:10.1007/978-1-4614-6846-2_9",
    abstract =     "Recent advances in symbolic regression (SR) have
    promoted the field into the early stages of commercial
    exploitation. This is the expected maturation history
    for an academic field which is progressing rapidly. The
    original published symbolic regression algorithms in
    (Koza 1994) have long since been replaced by techniques
    such as Pareto front, age layered population
    structures, and even age Pareto front optimisation. The
    lack of specific techniques for optimising embedded
    real numbers, in the original algorithms, has been
    replaced with sophisticated techniques for optimizing
    embedded constants. Symbolic regression is coming of
    age as a technology.
    
    As the discipline of Symbolic Regression (SR) has
    matured, the first commercial SR packages have
    appeared. There is at least one commercial package on
    the market for several years http://www.rmltech.com/.
    There is now at least one well documented commercial
    symbolic regression package available for Mathmatica
    www.evolved-analytics.com. There is at least one very
    well done open source symbolic regression package
    available for free download
    http://ccsl.mae.cornell.edu/eureqa. Yet, even as the
    sophistication of commercial SR packages increases,
    there have been glaring issues with SR accuracy even on
    simple problems (Korns 2011). The depth and breadth of
    SR adoption in industry and academia will be greatly
    affected by the demonstrable accuracy of available SR
    algorithms and tools.
    
    In this chapter we develop a complete public domain
    algorithm for modern symbolic regression which is
    reasonably competitive with current commercial SR
    packages, and calibrate its accuracy on a set of
    previously published sample problems. This algorithm is
    designed as a baseline for further public domain
    research on SR algorithm simplicity and accuracy. No
    claim is made placing this baseline algorithm on a par
    with commercial packages, especially as the commercial
    offerings can be expected to relentlessly improve in
    the future. However this baseline is a great
    improvement over the original published algorithms, and
    is an attempt to consolidate the latest published
    research into a simplified baseline algorithm of
    similar speed and accuracy.
    
    The baseline algorithm presented herein is called Age
    Weighted Pareto Optimisation. It is an amalgamation of
    recent published techniques in Pareto front
    optimization (Kotanchek et al., 2007), age layered
    population structures (Hornby 2006), age fitness Pareto
    optimization (Schmidt and Hipson 2010), and specialised
    embedded abstract constant optimization (Korns 2010).
    The complete pseudo code for the baseline algorithm is
    presented in this paper. It is developed step by step
    as enhancements to the original published SR algorithm
    (Koza 1992) with justifications for each enhancement.
    Before-after speed and accuracy comparisons are made
    for each enhancement on a series of previously
    published sample problems.",
    notes =        "part of \cite{Riolo:2012:GPTP} published after the
    workshop in 2013",
}

@Inbook{SRAccur,
    author="Korns, Michael F.",
    editor="Riolo, Rick
    and Vladislavleva, Ekaterina
    and Moore, Jason H.",
    title="Accuracy in Symbolic Regression",
    bookTitle="Genetic Programming Theory and Practice IX",
    year="2011",
    publisher="Springer New York",
    address="New York, NY",
    pages="129--151",
    isbn="978-1-4614-1770-5",
    doi="10.1007/978-1-4614-1770-5_8",
    url="http://dx.doi.org/10.1007/978-1-4614-1770-5_8"
}

@Inbook{GPConstAlter,
    author="Veenhuis, Christian B.",
    editor="Correia, Lu{\'i}s
    and Reis, Lu{\'i}s Paulo
    and Cascalho, Jos{\'e}",
    title="Structure-Based Constants in Genetic Programming",
    bookTitle="Progress in Artificial Intelligence: 16th Portuguese Conference on Artificial Intelligence, EPIA 2013, Angra do Hero{\'i}smo, Azores, Portugal, September 9-12, 2013. Proceedings",
    year="2013",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="126--137",
    isbn="978-3-642-40669-0",
    doi="10.1007/978-3-642-40669-0_12",
    url="http://dx.doi.org/10.1007/978-3-642-40669-0_12"
}

@article{GPBloat, 
    author    = { Marc-André Gardner and Christian Gagné and Marc Parizeau },
    title     = { Controlling Code Growth by Dynamically Shaping the Genotype Size Distribution },
    volume    = { 16 },
    number    = { 4 },
    pages     = { 455--498 },
    year      = { 2015 },
    journal   = { Genetic Programming and Evolvable Machines },
    web       = { http://dx.doi.org/10.1007/s10710-015-9242-8 }
} 

@inproceedings{GPHardness,
    author = {Poli, Riccardo and Vanneschi, Leonardo},
    title = {Fitness-proportional Negative Slope Coefficient As a Hardness Measure for Genetic Algorithms},
    booktitle = {Proceedings of the 9th Annual Conference on Genetic and Evolutionary Computation},
    series = {GECCO '07},
    year = {2007},
    isbn = {978-1-59593-697-4},
    location = {London, England},
    pages = {1335--1342},
    numpages = {8},
    url = {http://doi.acm.org/10.1145/1276958.1277209},
    doi = {10.1145/1276958.1277209},
    acmid = {1277209},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {negative slope coefficient, problem difficulty, theory},
}

@manual{sagemath,
    Key          = {SageMath},
    Author       = {The Sage Developers},
    Title        = {{S}ageMath, the {S}age {M}athematics {S}oftware {S}ystem ({V}ersion x.y.z)},
    note         = {{\tt http://www.sagemath.org}},
    Year         = {YYYY},
   }
   
@article{graphviz,
    author = {Emden R. Gansner and Stephen C. North},
    title = {An open graph visualization system and its applications to software engineering},
    journal = {SOFTWARE - PRACTICE AND EXPERIENCE},
    year = {2000},
    volume = {30},
    number = {11},
    pages = {1203--1233}
}

@article{PSOTutorial,
title = "Particle swarm optimization (PSO). A tutorial",
abstract = "Swarm-based algorithms emerged as a powerful family of optimization techniques, inspired by the collective behavior of social animals. In particle swarm optimization (PSO) the set of candidate solutions to the optimization problem is defined as a swarm of particles which may flow through the parameter space defining trajectories which are driven by their own and neighbors' best performances. In the present paper, the potential of particle swarm optimization for solving various kinds of optimization problems in chemometrics is shown through an extensive description of the algorithm (highlighting the importance of the proper choice of its metaparameters) and by means of selected worked examples in the fields of signal warping, estimation robust PCA solutions and variable selection.",
keywords = "Continue and discrete optimization, Particle swarm optimization (PSO), Swarm intelligence, Variable selection, Warping algorithms",
author = "Federico Marini and Beata Walczak",
year = "2015",
month = "12",
doi = "10.1016/j.chemolab.2015.08.020",
volume = "149",
pages = "153--165",
journal = "Chemometrics and Intelligent Laboratory Systems",
issn = "0169-7439",
publisher = "Elsevier",
} 

@inproceedings{PSOInertia,
  title={Inertia weight strategies in particle swarm optimization},
  author={Bansal, Jagdish Chand and Singh, PK and Saraswat, Mukesh and Verma, Abhishek and Jadon, Shimpi Singh and Abraham, Ajith},
  booktitle={Nature and Biologically Inspired Computing (NaBIC), 2011 Third World Congress on},
  pages={633--640},
  year={2011},
  organization={IEEE}
}

@misc{SwarmIntelligence,
  title={Swarm intelligence},
  author={Kennedy, James F and Kennedy, James and Eberhart, Russell C and Shi, Yuhui},
  year={2001},
  publisher={Morgan Kaufmann}
}

@Misc{sortedcontainers,
  author = {Grant Jenks and others},
  title =  {{SortedContainers}: Sorted list, dictionary and set types for {Python}},
  year =   {2014--},
  url =    "http://www.grantjenks.com/docs/sortedcontainers/",
  note =   {[Online; accessed <today>]}
}